# 2019年7月知乎大 V 数据分析
## 项目内容
* 抓取知乎粉丝数一万以上用户个人信息，包括回答数、文章数、粉丝数、获得收藏数、获得赞同数、收录文章数、收录回答数、关注的收藏夹、专栏；及粉丝数 10w 以上用户回答及文章详细信息；
* 根据知乎高关注度用户基本数据进行数据可视化分析，绘制图表包括：
   1. 用户回答数、文章数、粉丝数等基本数排名；
   2. 用户回答数、点赞数、粉丝数散点图；
   3. 粉丝数前 50 用户关系图；
   4. 10w 粉丝用户回答、文章随时间变化图。
## 项目思路
1. 知乎是以回答为主的知识社区，为分析知乎高关注用户的基本情况，从高关注用户**张佳玮**关注用户开始抓取粉丝数 1w 以上用户，并以此类推，直至抓取完毕；然后为获得回答数、粉丝数、点赞数等相关排名。于是依据**获取的用户数据**抓取知乎粉丝数 1w 以上用户主页文章、回答、获得赞同数等数据及详细的回答、文章数据；
2. 使用 scrapy 分别抓取用户数据并使用 mongodb 储存；
3. 使用可视化工具 pyecharts, 对数据进行可视化处理；
4. 整理分析。
## 运行环境
* python3.7
* windows
* jupyter notebook
* mongodb
## 运行依赖包
* pymongo
* scrapy
* pyecharts
* jieba
* wordcloud
## 文件说明
### code 
* **zhihu** scrapy 项目代码文件，粉丝数 1w 以上用户信息抓取代码；
* zhihu_plot.ipynb pyecharts 图表绘制文件。
### zhihu_html
* 里面包含可视化操作后的大部分文件，主要为 pyecharts 绘制的排行 zhihu_user.html 文件, 用户回答、文章随时间变化的 zhihu_p.html，以及词云。
### node
* 粉丝数前50的高关注用户关系图。
